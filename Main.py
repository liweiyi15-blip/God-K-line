import discord
from discord import app_commands
from discord.ext import tasks
import json
import os
from datetime import datetime, time, timedelta
import asyncio
import pandas as pd
import numpy as np
import pytz
from dotenv import load_dotenv
from collections import defaultdict
import aiohttp
import io
import matplotlib
import random

# [æ—¥å¿—é…ç½®]
import logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(levelname)s | %(message)s')

# --- å¼ºåˆ¶ä½¿ç”¨éäº¤äº’å¼åç«¯ ---
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import mplfinance as mpf

# --- åŠ è½½ç¯å¢ƒå˜é‡ ---
load_dotenv()

DISCORD_TOKEN = os.getenv("DISCORD_TOKEN")
FMP_API_KEY = os.getenv("FMP_API_KEY")

try:
    ALERT_CHANNEL_ID = int(os.getenv("ALERT_CHANNEL_ID"))
except (TypeError, ValueError):
    ALERT_CHANNEL_ID = 0
    logging.warning("ALERT_CHANNEL_ID not set or invalid.")

# --- å…¨å±€é…ç½® ---
MARKET_TIMEZONE = pytz.timezone('America/New_York')

SETTINGS_FILE = "/app/data/settings.json"
if not os.path.exists("/app/data"):
    SETTINGS_FILE = "settings.json"

# [é…ç½®] æ‰«ææ—¶é—´
TIME_MARKET_OPEN = time(9, 30)
TIME_MARKET_SCAN_START = time(10, 0) # 10ç‚¹æ‰å¼€å§‹æŠ¥
TIME_MARKET_CLOSE = time(16, 0)

# --- æ ¸å¿ƒç­–ç•¥é…ç½® (ä¼˜åŒ–ç‰ˆï¼šé˜²è¿½é«˜ï¼ŒæŠ“å¯åŠ¨ï¼Œèµ„é‡‘éªŒè¯) ---
CONFIG = {
    "filter": {
        # [é˜²è¿½é«˜] 60æ—¥æ¶¨å¹…é™åˆ¶
        # é€»è¾‘ï¼šå½“å‰æ”¶ç›˜ä»·ä¸èƒ½è¶…è¿‡ (è¿‡å»60å¤©æœ€ä½ä»· * 1.3)ã€‚
        # ä½œç”¨ï¼šå‰”é™¤é‚£äº›çŸ­æœŸå·²ç»æ¶¨äº†30%ä»¥ä¸Šçš„è‚¡ç¥¨ï¼Œé˜²æ­¢å»åšåˆ«äººçš„æ¥ç›˜ä¾ ã€‚
        "max_60d_gain": 0.3,

        # [é˜²è¿‡çƒ­] RSI è¶…ä¹°é™åˆ¶
        # é€»è¾‘ï¼šRSI(14) æŒ‡æ ‡ä¸èƒ½è¶…è¿‡ 55ã€‚
        # ä½œç”¨ï¼šRSIè¶…è¿‡55-70é€šå¸¸æ„å‘³ç€çŸ­çº¿è¿‡çƒ­ï¼Œå›è°ƒé£é™©å¤§ã€‚æˆ‘ä»¬åªåšåˆšå¯åŠ¨çš„ï¼Œä¸åšå·²ç»çƒ­è¿‡å¤´çš„ã€‚
        "max_rsi": 55,

        # [é˜²åç¦»] ä¹–ç¦»ç‡é™åˆ¶
        # é€»è¾‘ï¼šç°ä»·ä¸èƒ½æ¯” 50æ—¥å‡çº¿ (MA50) é«˜å‡º 20%ã€‚
        # ä½œç”¨ï¼šè‚¡ä»·åƒæ©¡çš®ç­‹ï¼Œç¦»å‡çº¿å¤ªè¿œä¼šè¢«æ‹‰å›æ¥ã€‚é™åˆ¶è¿™ä¸ªèƒ½é¿å…ä¹°åœ¨â€œå†²é«˜å›è½â€çš„å‰å¤œã€‚
        "max_bias_50": 0.20,

        # [é˜²æŠ›å‹] ä¸Šå½±çº¿é™åˆ¶
        # é€»è¾‘ï¼šä¸Šå½±çº¿é•¿åº¦ä¸èƒ½è¶…è¿‡ Kçº¿æ€»é•¿åº¦çš„ 40%ã€‚
        # ä½œç”¨ï¼šé•¿ä¸Šå½±çº¿ï¼ˆé¿é›·é’ˆï¼‰è¯´æ˜ä¸Šæ–¹å–ç›˜å‹åŠ›å·¨å¤§ï¼Œè¿™ç§ç¥¨å†²ä¸Šå»å®¹æ˜“è¢«æ‰“ä¸‹æ¥ï¼Œè¦è¿‡æ»¤ã€‚
        "max_upper_shadow": 0.4,

        # [é˜²ç–¯ç‰›] å•æ—¥æ¶¨å¹…é™åˆ¶
        # é€»è¾‘ï¼šå½“å¤©æ¶¨å¹…ä¸èƒ½è¶…è¿‡ 7%ã€‚
        # ä½œç”¨ï¼šé˜²æ­¢è¿½è¿›å·²ç»è¢«çˆ†ç‚’çš„å¦–è‚¡ï¼Œé£é™©ä¸å¯æ§ã€‚
        "max_day_change": 0.7,

        # [èƒ½é‡é—¨æ§›] é‡æ¯”é˜ˆå€¼
        # é€»è¾‘ï¼š(é¢„æµ‹)æˆäº¤é‡ å¿…é¡»æ˜¯ 20æ—¥å‡é‡ çš„ 1.3å€ä»¥ä¸Šã€‚
        # ä½œç”¨ï¼šæ— é‡ä¸çªç ´ã€‚ç¡®ä¿å½“å‰æ˜¯æœ‰èµ„é‡‘å…³æ³¨çš„ï¼Œä¸æ˜¯æ•£æˆ·è‡ªå¨±è‡ªä¹ã€‚
        "min_vol_ratio": 1.3,
        
        # --- [æ ¸å¿ƒ] å¸ƒæ—å¸¦(BB Squeeze) ç›¸å…³å‚æ•° ---
        
        # [è“„åŠ¿æ¡ä»¶] æŒ¤å‹é˜ˆå€¼ (æ˜¨æ—¥)
        # é€»è¾‘ï¼šæ˜¨å¤©çš„å¸ƒæ—å¸¦å¸¦å®½ (Width) å¿…é¡»å°äº 0.08 (8%)ã€‚
        # ä½œç”¨ï¼šå¯»æ‰¾é‚£äº›é•¿æœŸæ¨ªç›˜ã€æ³¢åŠ¨æå°ã€åƒå‹ç¼©å¼¹ç°§ä¸€æ ·çš„è‚¡ç¥¨ã€‚æ•°å€¼è¶Šå°ï¼Œç›˜æ•´è¶Šæè‡´ã€‚
        "min_bb_squeeze_width": 0.08,

        # [å¯åŠ¨æ¡ä»¶] æ‰©å¼ é˜ˆå€¼ (ä»Šæ—¥)
        # é€»è¾‘ï¼šä»Šå¤©çš„å¸ƒæ—å¸¦å¸¦å®½å¿…é¡»æ‰©å¤§åˆ° 0.095 (9.5%) ä»¥ä¸Šã€‚
        # ä½œç”¨ï¼šç¡®è®¤â€œå¼¹ç°§å¼¹å¼€äº†â€ã€‚å¿…é¡»é…åˆä¸Šé¢çš„ 0.08 ä½¿ç”¨ï¼Œä»£è¡¨ä»â€œæé™â€è½¬ä¸ºâ€œå¯åŠ¨â€ã€‚
        "min_bb_expand_width": 0.095,

        # [ä½ç½®æ¡ä»¶] åº•éƒ¨ä½ç½®é˜ˆå€¼
        # é€»è¾‘ï¼šå½“å‰ä»·æ ¼å¤„äºè¿‡å»60å¤©ä»·æ ¼åŒºé—´çš„ 30% åˆ†ä½ä»¥ä¸‹ã€‚
        # ä½œç”¨ï¼š(ç°ä»·-æœ€ä½ä»·)/(æœ€é«˜ä»·-æœ€ä½ä»·) <= 0.3ã€‚ç¡®ä¿æˆ‘ä»¬æ˜¯åœ¨åº•éƒ¨æŠ„åº•ï¼Œè€Œä¸æ˜¯åœ¨åŠå±±è…°æ¥é£åˆ€ã€‚
        "max_bottom_pos": 0.30,
        
        # [è¶‹åŠ¿æ½œèƒ½] ADX é—¨æ§›
        # é€»è¾‘ï¼šADX å¿…é¡»å¤§äº 15ã€‚
        # ä½œç”¨ï¼šé˜²æ­¢é€‰åˆ°é‚£ç§å½»åº•æ²¡äººç©çš„â€œæ­»è‚¡â€ã€‚å³ä½¿åœ¨ç›˜æ•´ï¼Œå†…éƒ¨ä¹Ÿè¦æœ‰ä¸€å®šçš„åŠ¨èƒ½ã€‚
        "min_adx_for_squeeze": 15
    },

    "pattern": {
        # [å½¢æ€è¯†åˆ«] æ¢è½´ç‚¹çª—å£
        # ä½œç”¨ï¼šè¯†åˆ«é˜»åŠ›çº¿å’Œæ”¯æ’‘çº¿æ—¶ï¼Œå¾€å‰å’Œå¾€åçœ‹ 5 å¤©æ¥ç¡®å®šé«˜ä½ç‚¹ã€‚5 æ˜¯å‘¨çº¿çº§åˆ«çš„ç»å…¸å‚æ•°ã€‚
        "pivot_window": 5
    },

    "system": {
        # [é˜²åˆ·å±] å†·å´æ—¶é—´
        # ä½œç”¨ï¼šä¸€åªè‚¡ç¥¨æŠ¥è­¦åï¼Œ3å¤©å†…ä¸å†æŠ¥è­¦ã€‚é˜²æ­¢åŒä¸€åªç¥¨å¤©å¤©å“ã€‚
        "cooldown_days": 3,

        # [é˜²æ‹¥å µ] æ¯æ¬¡æ‰«ææœ€å¤§å‘å›¾æ•°
        # ä½œç”¨ï¼šæ¯æ¬¡æ‰«ææœ€å¤šå‘ 5 å¼ å›¾ï¼Œé¿å…Discordé¢‘é“è¢«åˆ·å±ã€‚
        "max_charts_per_scan": 5,

        # [æ•°æ®æº] è·å–å†å²æ•°æ®é•¿åº¦
        # ä½œç”¨ï¼šå‘ API è¯·æ±‚è¿‡å» 400 å¤©çš„æ•°æ®ï¼Œä¿è¯å‡çº¿è®¡ç®—å‡†ç¡®ã€‚
        "history_days": 400
    },

    "SCORE": { 
        # [åŠæ ¼çº¿] æœ€ä½æŠ¥è­¦åˆ†æ•°
        # ä½œç”¨ï¼šæ€»åˆ†ä½äº 70 åˆ†çš„è‚¡ç¥¨ï¼Œå³ä½¿æ»¡è¶³è¿‡æ»¤æ¡ä»¶ä¹Ÿä¸æŠ¥è­¦ã€‚
        "MIN_ALERT_SCORE": 70, 

        # --- [æ‰“åˆ†æƒé‡ç³»ç»Ÿ] ---
        "WEIGHTS": {
            # 1. å½¢æ€çªç ´ (40åˆ†)
            # å«ä¹‰ï¼šçªç ´äº†å‰æœŸç”»å‡ºçš„é˜»åŠ›çº¿è¶‹åŠ¿çº¿ã€‚æœ€å¼ºçš„ä¹°å…¥ä¿¡å·ä¹‹ä¸€ã€‚
            "PATTERN_BREAK": 40,

            # 2. Nx çªç ´ (35åˆ†)
            # å«ä¹‰ï¼šæ”¶ç›˜ä»·ç«™ä¸Šäº† Nx è“è‰²å‡çº¿ç³»ç»Ÿã€‚ä»£è¡¨è¶‹åŠ¿è½¬å¤šã€‚
            "NX_BREAKOUT": 35,

            # 3. å¸ƒæ—å¸¦æŒ¤å‹å¯åŠ¨ (30åˆ†) [æ ¸å¿ƒç­–ç•¥]
            # å«ä¹‰ï¼šæ»¡è¶³ä¸Šé¢çš„ BB Squeeze é€»è¾‘ (ä½ä½+æŒ¤å‹+å¼€å£)ã€‚è¿™æ˜¯ä½ ç›®å‰çš„ä¸»ç­–ç•¥ã€‚
            "BB_SQUEEZE": 30,

            # 4. è“æ¢¯å›è¸© (20åˆ†)
            # å«ä¹‰ï¼šä¸Šæ¶¨é€”ä¸­çš„å›è°ƒï¼Œè¸©ç¨³äº†è“çº¿æ”¯æ’‘ã€‚å±äºâ€œä¸Šè½¦æœºä¼šâ€ã€‚
            "GOD_TIER_NX": 20,

            # 5. å¼ºè¶‹åŠ¿ ADX (20åˆ†)
            # å«ä¹‰ï¼šADX>25 ä¸” PDI>MDIã€‚ä»£è¡¨æ­£å¤„äºä¸»å‡æµªä¸­ã€‚
            "STRONG_ADX": 20,
            
            # 6. è¶‹åŠ¿æ¿€æ´» (20åˆ†)
            # å«ä¹‰ï¼šADX ç»“æŸç›˜æ•´ï¼Œåˆšåˆšæ‹å¤´å‘ä¸Šã€‚ä»£è¡¨è¡Œæƒ…åˆšç‚¹ç«ã€‚
            "ADX_ACTIVATION": 20,

            # 7. OBV èµ„é‡‘éªŒè¯ (15åˆ†) [æ–°åŠ å…¥]
            # å«ä¹‰ï¼šOBV å¤„äºä¸Šå‡è¶‹åŠ¿ (å¤§äº20æ—¥å‡çº¿) ä¸”è¿‘æœŸåœ¨æµå…¥ã€‚ç”¨äºå¼¥è¡¥é‡æ¯”é¢„æµ‹çš„ä¸å‡†ã€‚
            "OBV_TREND_UP": 15,

            # 8. æŠ›å”®é«˜æ½® (12åˆ†)
            # å«ä¹‰ï¼šè·Œç ´å¸ƒæ—ä¸‹è½¨+å·¨é‡+é•¿ä¸‹å½±ã€‚ä»£è¡¨ææ…Œç›˜æ¶Œå‡ºï¼Œå¯èƒ½æ˜¯ç»ä½³çš„è¶…è·Œåå¼¹ç‚¹ã€‚
            "CAPITULATION": 12,

            # 9. å·¨é‡ (10åˆ†)
            # å«ä¹‰ï¼šæˆäº¤é‡æ˜¯å‡é‡çš„2å€ä»¥ä¸Šã€‚
            "HEAVY_VOLUME": 10,

            # 10. MACD é‡‘å‰ / åº•èƒŒç¦» (10åˆ†)
            # å«ä¹‰ï¼šç»å…¸çš„æŒ‡æ ‡ä¿¡å·ã€‚
            "MACD_ZERO_CROSS": 10,
            "MACD_DIVERGE": 10,

            # 11. KDJ åå‡» (8åˆ†)
            # å«ä¹‰ï¼šJçº¿è§¦åº•åå¼¹ã€‚
            "KDJ_REBOUND": 8,            

            # 12. Kçº¿å½¢æ€ (5åˆ†)
            # å«ä¹‰ï¼šå‡ºç°æ—©æ™¨ä¹‹æ˜Ÿã€åæ²¡å½¢æ€ç­‰ã€‚ä½œä¸ºè¾…åŠ©åŠ åˆ†ã€‚
            "CANDLE_PATTERN": 5
        },
        
        # [è¯„çº§æ ‡ç­¾] æ ¹æ®åˆ†æ•°ç»™å‡ºçš„ Emoji
        "EMOJI": { 
            100: "TOP", 90: "HIGH", 80: "MID", 70: "LOW", 60: "TEST"
        }
    }
}

# --- é™æ€è‚¡ç¥¨æ±  ---
STOCK_POOLS = {
    "NASDAQ_100": [
        "AAPL", "MSFT", "AMZN", "NVDA", "META", "GOOGL", "GOOG", "TSLA", "AVGO", "ADBE", 
        "COST", "PEP", "CSCO", "NFLX", "AMD", "TMUS", "INTC", "CMCSA", "AZN", "QCOM", 
        "TXN", "AMGN", "HON", "INTU", "SBUX", "GILD", "BKNG", "DIOD", "MDLZ", "ISRG", 
        "REGN", "LRCX", "VRTX", "ADP", "ADI", "MELI", "KLAC", "PANW", "SNPS", "CDNS", 
        "CHTR", "MAR", "CSX", "ORLY", "MNST", "NXPI", "CTAS", "FTNT", "WDAY", "DXCM", 
        "PCAR", "KDP", "PAYX", "IDXX", "AEP", "LULU", "EXC", "BIIB", "ADSK", "XEL", 
        "ROST", "MCHP", "CPRT", "DLTR", "EA", "FAST", "CTSH", "VRSK", "CSGP", "ODFL", 
        "EBAY", "ILMN", "GFS", "ALGN", "TEAM", "CDW", "WBD", "SIRI", "ZM", "ENPH", 
        "JD", "PDD", "LCID", "RIVN", "ZS", "DDOG", "CRWD", "TTD", "BKR", "CEG", "GEHC", 
        "ON", "FANG"
    ],
    "GOD_TIER": [
        "NVDA", "AMD", "TSM", "SMCI", "AVGO", "ARM", "PLTR", "AI", "PATH", "BABA", 
        "PDD", "BIDU", "NIO", "LI", "XPEV", "COIN", "MARA", "MSTR"
    ]
}

settings = {}

# --- è¾…åŠ©å‡½æ•° ---
def load_settings():
    global settings
    try:
        if os.path.exists(SETTINGS_FILE):
            with open(SETTINGS_FILE, 'r', encoding='utf-8') as f:
                settings = json.load(f)
        else:
            settings = {"users": {}, "signal_history": {}}
            save_settings()
    except Exception as e:
        logging.error(f"Error loading settings: {e}")
        settings = {"users": {}, "signal_history": {}}

def save_settings():
    try:
        dir_name = os.path.dirname(SETTINGS_FILE)
        if dir_name and not os.path.exists(dir_name):
            os.makedirs(dir_name, exist_ok=True)
        with open(SETTINGS_FILE, 'w', encoding='utf-8') as f:
            json.dump(settings, f, indent=4)
    except Exception as e:
        logging.error(f"Error saving settings: {e}")

def get_user_data(user_id):
    uid_str = str(user_id)
    if "users" not in settings: settings["users"] = {}
    if uid_str not in settings["users"]:
        settings["users"][uid_str] = {"stocks": [], "daily_status": {}}
    return settings["users"][uid_str]

# --- æ ¸å¿ƒé€»è¾‘ (æŒ‡æ ‡è®¡ç®—) ---
def calculate_nx_indicators(df):
    cols = ['open', 'high', 'low', 'close', 'volume']
    for c in cols:
        df[c] = pd.to_numeric(df[c], errors='coerce')
      
    df = df[df['close'] > 0]
      
    # 1. Nx å‡çº¿
    df['Nx_Blue_UP'] = df['high'].ewm(span=24, adjust=False).mean()
    df['Nx_Blue_DW'] = df['low'].ewm(span=23, adjust=False).mean()
    df['Nx_Yellow_UP'] = df['high'].ewm(span=89, adjust=False).mean()
    df['Nx_Yellow_DW'] = df['low'].ewm(span=90, adjust=False).mean()
      
    # 2. MACD
    price_col = 'close'
    exp12 = df[price_col].ewm(span=12, adjust=False).mean()
    exp26 = df[price_col].ewm(span=26, adjust=False).mean()
    df['DIF'] = exp12 - exp26
    df['DEA'] = df['DIF'].ewm(span=9, adjust=False).mean()
    df['MACD'] = (df['DIF'] - df['DEA']) * 2
      
    # 3. RSI 
    delta = df[price_col].diff()
    gain = (delta.clip(lower=0)).rolling(window=14).mean()
    loss = (-delta.clip(upper=0)).rolling(window=14).mean()
      
    rs = gain / loss.replace(0, 1e-9)
    df['RSI'] = 100 - (100 / (1 + rs))
      
    # 4. Volume MA
    df['Vol_MA20'] = df['volume'].rolling(window=20).mean()
      
    # 5. ATR
    df['tr1'] = df['high'] - df['low']
    df['tr2'] = abs(df['high'] - df['close'].shift(1))
    df['tr3'] = abs(df['low'] - df['close'].shift(1))
    df['TR'] = df[['tr1', 'tr2', 'tr3']].max(axis=1)
    df['ATR'] = df['TR'].rolling(window=14).mean()

    # 6. BB
    df['BB_Mid'] = df['close'].rolling(20).mean()
    df['BB_Std'] = df['close'].rolling(20).std()
    df['BB_Up'] = df['BB_Mid'] + 2 * df['BB_Std']
    df['BB_Low'] = df['BB_Mid'] - 2 * df['BB_Std']
    df['BB_Width'] = (df['BB_Up'] - df['BB_Low']) / df['BB_Mid']

    # 7. KDJ
    low_min = df['low'].rolling(9).min()
    high_max = df['high'].rolling(9).max()
    rsv_denom = (high_max - low_min).replace(0, 1e-9)
    df['RSV'] = (df['close'] - low_min) / rsv_denom * 100
    df['K'] = df['RSV'].ewm(com=2).mean() 
    df['D'] = df['K'].ewm(com=2).mean()
    df['J'] = 3 * df['K'] - 2 * df['D']

    # 8. ADX / DMI ç³»ç»Ÿ
    alpha = 1/14
    df['up_move'] = df['high'] - df['high'].shift(1)
    df['down_move'] = df['low'].shift(1) - df['low']
    df['pdm'] = np.where((df['up_move'] > df['down_move']) & (df['up_move'] > 0), df['up_move'], 0)
    df['mdm'] = np.where((df['down_move'] > df['up_move']) & (df['down_move'] > 0), df['down_move'], 0)
      
    df['TR_s'] = df['TR'].ewm(alpha=alpha, adjust=False).mean()
    df['PDM_s'] = df['pdm'].ewm(alpha=alpha, adjust=False).mean()
    df['MDM_s'] = df['mdm'].ewm(alpha=alpha, adjust=False).mean()
      
    tr_s_safe = df['TR_s'].replace(0, 1e-9)
    df['PDI'] = 100 * (df['PDM_s'] / tr_s_safe)
    df['MDI'] = 100 * (df['MDM_s'] / tr_s_safe)
      
    dx_denom = (df['PDI'] + df['MDI']).replace(0, 1e-9)
    df['DX'] = 100 * abs(df['PDI'] - df['MDI']) / dx_denom
    df['ADX'] = df['DX'].ewm(alpha=alpha, adjust=False).mean()

    # 9. ä¹–ç¦»ç‡ (Bias)
    df['MA50'] = df['close'].rolling(50).mean()
    ma50_safe = df['MA50'].replace(0, np.nan) 
    df['BIAS_50'] = (df['close'] - ma50_safe) / ma50_safe

    # 10. Kçº¿å½¢æ€ç‰¹å¾
    candle_range = (df['high'] - df['low']).replace(0, 1e-9)
    upper_shadow = np.where(df['close'] >= df['open'], df['high'] - df['close'], df['high'] - df['open'])
    df['Upper_Shadow_Ratio'] = upper_shadow / candle_range

    # 11. [æ–°å¢] OBV (èƒ½é‡æ½®)
    # è®¡ç®—ä»·æ ¼å˜åŒ–æ–¹å‘: æ¶¨=+1, è·Œ=-1, å¹³=0
    obv_sign = np.sign(df['close'].diff()).fillna(0)
    df['OBV'] = (df['volume'] * obv_sign).cumsum()
    # è®¡ç®— OBV çš„ 20 æ—¥å‡çº¿ï¼Œç”¨äºåˆ¤æ–­èµ„é‡‘è¶‹åŠ¿
    df['OBV_MA20'] = df['OBV'].rolling(window=20).mean()

    return df

def process_dataframe_sync(hist_data):
    if not hist_data: return None
    df = pd.DataFrame(hist_data)
    if 'date' not in df.columns: return None
    df['date'] = pd.to_datetime(df['date'])
    df = df.set_index('date').sort_index(ascending=True)
    return calculate_nx_indicators(df)

def merge_and_recalc_sync(df, quote):
    if df is None or quote is None: return df
    try:
        quote_time = pd.to_datetime(quote['timestamp'], unit='s').tz_localize('UTC').tz_convert(MARKET_TIMEZONE)
        quote_date = quote_time.normalize().tz_localize(None) 
          
        last_idx = df.index[-1]
        last_date = pd.to_datetime(last_idx).normalize()
        if last_date.tzinfo is not None:
             last_date = last_date.tz_localize(None)

        current_price = quote['price']
        safe_high = max(quote['dayHigh'], current_price, quote['open'])
        safe_low = min(quote['dayLow'], current_price, quote['open'])

        new_row = {
            'open': quote['open'],
            'high': safe_high,
            'low': safe_low,
            'close': current_price,
            'volume': quote['volume'],
            'date': quote_date 
        }
          
        df_mod = df.copy()
          
        if last_date == quote_date:
            for col in ['open', 'high', 'low', 'close', 'volume']:
                if col == 'high':
                    df_mod.at[last_idx, col] = max(df_mod.at[last_idx, col], new_row[col])
                elif col == 'low':
                    df_mod.at[last_idx, col] = min(df_mod.at[last_idx, col], new_row[col])
                else:
                    df_mod.at[last_idx, col] = new_row[col]
        elif last_date < quote_date:
            new_df = pd.DataFrame([new_row])
            new_df = new_df.set_index('date')
            df_mod = pd.concat([df_mod, new_df])
          
        if 'marketCap' in quote:
            df_mod.attrs['marketCap'] = quote['marketCap']
            
        return calculate_nx_indicators(df_mod)
        
    except Exception as e:
        logging.error(f"[Merge Error] {e}")
        return df

def _safely_process_fmp_data(data, sym):
    try:
        if isinstance(data, list) and len(data) > 0 and 'date' in data[0] and 'close' in data[0]:
            return process_dataframe_sync(data)
        elif isinstance(data, dict) and 'historical' in data:
            return process_dataframe_sync(data['historical'])
        elif isinstance(data, list) and len(data) > 0 and 'historical' in data[0]:
            for item in data:
                if item.get('symbol') == sym:
                    return process_dataframe_sync(item['historical'])
        return None
    except Exception as e:
        logging.error(f"[Data Process Error] {sym}: {e}")
        return None

# [ä¿®æ”¹] ä¼˜åŒ–åçš„å†å²æ•°æ®è·å–ï¼šé™ä½å¹¶å‘ï¼Œå¢åŠ é‡è¯•
async def fetch_historical_batch(symbols: list, days=None):
    if not symbols: return {}
    if days is None: days = CONFIG["system"]["history_days"]
      
    results = {}
    now = datetime.now()
    from_date = (now - timedelta(days=days + 60)).strftime("%Y-%m-%d") 
    to_date = now.strftime("%Y-%m-%d")
    
    # [ä¼˜åŒ–] é™åˆ¶ä¸º 3 å¹¶å‘
    connector = aiohttp.TCPConnector(limit=3)
    semaphore = asyncio.Semaphore(3)
      
    headers = {
        "User-Agent": "Mozilla/5.0 (StockBot/1.0)",
        "Accept": "application/json"
    }

    async def fetch_single(session, sym):
        url = f"https://financialmodelingprep.com/stable/historical-price-eod/full?symbol={sym}&from={from_date}&to={to_date}&apikey={FMP_API_KEY}"
        async with semaphore:
            retries = 3
            for i in range(retries):
                try:
                    async with session.get(url, ssl=False) as response:
                        if response.status == 429:
                            wait_time = 3 * (2 ** i) # 3s, 6s, 12s
                            logging.warning(f"[429 Rate Limit] {sym}. Retry {i+1}/{retries} in {wait_time}s...")
                            await asyncio.sleep(wait_time)
                            continue # é‡è¯•
                          
                        if response.status == 200:
                            data = await response.json()
                            df = await asyncio.to_thread(_safely_process_fmp_data, data, sym)
                            if df is not None and not df.empty:
                                results[sym] = df
                            else:
                                logging.warning(f"[æ•°æ®ä¸ºç©º] {sym}")
                            break # æˆåŠŸé€€å‡ºå¾ªç¯
                        else:
                            logging.error(f"[HTTP é”™è¯¯] {sym} Status: {response.status}")
                            break
                except Exception as e:
                    logging.error(f"[å¼‚å¸¸] {sym}: {e}")
                    break
            # [ä¼˜åŒ–] æ¯æ¬¡è¯·æ±‚åç¨å¾®åœé¡¿ï¼Œä¿æŠ¤ API
            await asyncio.sleep(0.5)

    async with aiohttp.ClientSession(headers=headers, connector=connector) as session:
        tasks_list = [fetch_single(session, sym) for sym in symbols]
        await asyncio.gather(*tasks_list)
    return results

# [ä¿®æ”¹] ä¼˜åŒ–åçš„å®æ—¶æŠ¥ä»·è·å–ï¼šé™ä½å¹¶å‘ï¼Œå¢åŠ é‡è¯•
async def fetch_realtime_quotes(symbols: list):
    if not symbols: return {}
    quotes_map = {}
    
    # [ä¼˜åŒ–] é™åˆ¶ä¸º 5 å¹¶å‘
    connector = aiohttp.TCPConnector(limit=5)
    semaphore = asyncio.Semaphore(5)
    headers = {"User-Agent": "StockBot/1.0", "Accept": "application/json"}
      
    async def fetch_single_quote(session, sym):
        url = f"https://financialmodelingprep.com/stable/quote?symbol={sym}&apikey={FMP_API_KEY}"
        async with semaphore:
            retries = 3
            for i in range(retries):
                try:
                    async with session.get(url, ssl=False) as response:
                        if response.status == 429:
                            wait_time = 2 * (2 ** i)
                            logging.warning(f"[429 Rate Limit] Quote {sym}. Retry {i+1}/{retries} in {wait_time}s...")
                            await asyncio.sleep(wait_time)
                            continue

                        if response.status == 200:
                            data = await response.json()
                            if isinstance(data, list):
                                for item in data:
                                    s = item.get('symbol')
                                    if s: quotes_map[s] = item
                            elif isinstance(data, dict):
                                 s = data.get('symbol')
                                 if s: quotes_map[s] = data
                            break
                        else:
                             logging.error(f"[Quote Error] {sym} Status: {response.status}")
                             break
                except Exception as e:
                    logging.error(f"[Quote Exception] {sym}: {e}")
                    break
            await asyncio.sleep(0.2)

    async with aiohttp.ClientSession(headers=headers, connector=connector) as session:
        tasks_list = [fetch_single_quote(session, sym) for sym in symbols]
        await asyncio.gather(*tasks_list)
    return quotes_map

# [æ–°å¢] ä¸“é—¨è·å–å¤§ç›˜æŒ‡æ•° (Light Endpoint)
async def fetch_market_index_data(days=60):
    now = datetime.now()
    # ä»¥æ­¤å‰æ¨è¶³å¤Ÿçš„æ—¶é—´ä»¥ç¡®ä¿è¦†ç›–å›æµ‹æ‰€éœ€çš„20å¤©åæ•°æ®
    from_date = (now - timedelta(days=days + 30)).strftime("%Y-%m-%d")
    to_date = now.strftime("%Y-%m-%d")
    
    # ä½¿ç”¨ä½ æŒ‡å®šçš„ URL æ ¼å¼è·å–çº³æŒ‡ (^IXIC)
    url = f"https://financialmodelingprep.com/stable/historical-price-eod/light?symbol=%5EIXIC&from={from_date}&to={to_date}&apikey={FMP_API_KEY}"
    
    async with aiohttp.ClientSession() as session:
        try:
            async with session.get(url) as response:
                if response.status == 200:
                    data = await response.json()
                    if data and isinstance(data, list):
                        df = pd.DataFrame(data)
                        if 'date' in df.columns and 'price' in df.columns:
                            df['date'] = pd.to_datetime(df['date'])
                            # ç¡®ä¿æŒ‰æ—¶é—´æ­£åºæ’åˆ— (æ—§->æ–°)ï¼Œæ–¹ä¾¿ iloc ç´¢å¼•åç§»
                            df = df.set_index('date').sort_index(ascending=True)
                            return df
        except Exception as e:
            logging.error(f"[Market Index Error] {e}")
    return None

def find_pivots(df, window=5):
    highs = df['high'].values
    lows = df['low'].values
    dates = df.index
      
    pivots_high = [] 
    pivots_low = []
      
    start_idx = max(0, len(df) - 60)
      
    for i in range(start_idx + window, len(df) - window):
        is_high = True
        is_low = True
        current_high = highs[i]
        current_low = lows[i]
        
        for j in range(1, window + 1):
            if highs[i-j] >= current_high or highs[i+j] > current_high:
                is_high = False
            if lows[i-j] <= current_low or lows[i+j] < current_low:
                is_low = False
        
        if is_high: pivots_high.append((dates[i], current_high, i))
        if is_low: pivots_low.append((dates[i], current_low, i))
            
    return pivots_high, pivots_low

def identify_patterns(df):
    """
    æ— é™å»¶é•¿ç”»çº¿ + 3.5% æ–°é²œåº¦æ£€æŸ¥
    """
    if len(df) < 30: return None, [], []
      
    pivots_high, pivots_low = find_pivots(df, window=4)
      
    res_line, sup_line = [], []
    pattern_name = None

    vis_start_idx = max(0, len(df) - 80) 
    curr_idx = len(df) - 1
      
    t_end = df.index[curr_idx]
    t_start = df.index[vis_start_idx]

    if len(pivots_high) >= 2:
        ph1, ph2 = pivots_high[-2], pivots_high[-1]
        x1, y1 = ph1[2], ph1[1]
        x2, y2 = ph2[2], ph2[1]
        
        if x2 != x1:
            m = (y2 - y1) / (x2 - x1)
            c = y1 - m * x1
            
            p_start = m * vis_start_idx + c
            p_end = m * curr_idx + c
            
            res_line = [[(t_start, p_start), (t_end, p_end)]]
            
            if len(pivots_low) >= 2:
                pl1, pl2 = pivots_low[-2], pivots_low[-1]
                lx1, ly1 = pl1[2], pl1[1]
                lx2, ly2 = pl2[2], pl2[1]
                
                if lx2 != lx1:
                    lm = (ly2 - ly1) / (lx2 - lx1)
                    lc = ly1 - lm * lx1
                    
                    lp_start = lm * vis_start_idx + lc
                    lp_end = lm * curr_idx + lc
                    
                    sup_line = [[(t_start, lp_start), (t_end, lp_end)]]
                    
                    curr_price = df['close'].iloc[-1]
                    res_today = m * curr_idx + c
                    
                    if m < 0.005 and (lm > m + 0.01):
                         if curr_price > res_today:
                             # Freshness Check
                             if curr_price < res_today * 1.035:
                                 pattern_name = "å½¢æ€çªç ´ (åˆšå¯åŠ¨)"
    
    return pattern_name, res_line, sup_line

def detect_candle_patterns(df):
    if len(df) < 5: return []
    patterns = []
    curr = df.iloc[-1]
    prev1 = df.iloc[-2]
    prev2 = df.iloc[-3]
    curr_body = abs(curr['close'] - curr['open'])
    prev1_body = abs(prev1['close'] - prev1['open'])
    prev2_body = abs(prev2['close'] - prev2['open'])
      
    is_bullish_engulfing = (prev1['close'] < prev1['open']) and \
                           (curr['close'] > curr['open']) and \
                           (curr['open'] < prev1['close']) and \
                           (curr['close'] > prev1['open'])
    if is_bullish_engulfing: patterns.append("Bullish Engulfing (åæ²¡)")
        
    is_morning_star = (prev2['close'] < prev2['open']) and \
                      (prev1_body < prev2_body * 0.3) and \
                      (curr['close'] > curr['open']) and \
                      (curr['close'] > (prev2['open'] + prev2['close'])/2)
    if is_morning_star: patterns.append("Morning Star (æ—©æ™¨ä¹‹æ˜Ÿ)")
        
    lower_shadow = min(curr['close'], curr['open']) - curr['low']
    upper_shadow = curr['high'] - max(curr['close'], curr['open'])
    if lower_shadow > 2 * curr_body and upper_shadow < 0.5 * curr_body:
        patterns.append("Hammer (é”¤å­çº¿)")

    return patterns

def get_volume_projection_factor(ny_now, minutes_elapsed):
    TOTAL_MINUTES = 390
    if minutes_elapsed <= 10: return 13.0
    elif minutes_elapsed <= 60: return 13.0 - (13.0 - 8.0) * (minutes_elapsed - 10) / 50
    else: return 8.0 - (8.0 - 4.0) * (minutes_elapsed - 60) / (TOTAL_MINUTES - 60)

# [æ–°å¢] è®¡ç®—åŒçº¿ï¼šæ­¢æŸä½ (ATR) å’Œ æ”¯æ’‘ä½ (Structure)
def calculate_risk_levels(df):
    """
    è¿”å› (stop_loss, support)
    Stop Loss: 2.8x ATR (Hard Risk Control)
    Support: Pivot Low (Structural Level)
    """
    curr_close = df['close'].iloc[-1]
    atr = df['ATR'].iloc[-1] if 'ATR' in df.columns else curr_close * 0.05
      
    # 1. è®¡ç®—æ­¢æŸ (Stop Loss) - å›å½’ 2.8x ATR
    stop_loss = curr_close - (2.8 * atr)
      
    # 2. è®¡ç®—æ”¯æ’‘ (Support) - æ‰¾å‰ä½ç»“æ„
    _, pivots_low = find_pivots(df, window=5)
    support = stop_loss # é»˜è®¤ fallback
      
    if pivots_low:
        last_pivot_low = pivots_low[-1][1]
        # å¦‚æœå‰ä½åœ¨ç°ä»·ä¸‹æ–¹ï¼Œä¸”ä¸è¦ç¦»å¾—å¤ªè¿œ(æ¯”å¦‚è·Œäº†50%)ï¼Œåˆ™ä½œä¸ºæ”¯æ’‘
        if last_pivot_low < curr_close:
             support = last_pivot_low
             
    return stop_loss, support

# --- æ ¸å¿ƒä¿¡å·æ£€æŸ¥å‡½æ•° ---
def check_signals_sync(df):
    if len(df) < 60: return False, 0, "æ•°æ®ä¸è¶³", [], []
      
    last_date = df.index[-1].date()
    today_date = datetime.now(MARKET_TIMEZONE).date()
      
    if (today_date - last_date).days > 4:
        return False, 0, f"DATA_STALE: æ•°æ®ä¸¥é‡æ»å ({last_date})", [], []

    curr = df.iloc[-1]
    prev = df.iloc[-2]
    triggers = []
    score = 0
    weights = CONFIG["SCORE"]["WEIGHTS"]
    violations = [] 

    # --- åŸºç¡€ç»Ÿè®¡æ•°æ® (ç”¨äºä½ç½®åˆ¤æ–­) ---
    low_60 = df['low'].tail(60).min()
    high_60 = df['high'].tail(60).max()
    
    # [ä¿®æ”¹ Fix 1] ä¿®å¤é€»è¾‘é”™è¯¯: åº”è¯¥æ˜¯ Low * (1 + 0.6) = 1.6å€
    if curr['close'] > low_60 * (1 + CONFIG["filter"]["max_60d_gain"]): 
        violations.append("RISK: çŸ­æœŸæ¶¨å¹…è¿‡å¤§")
        
    prev_close_safe = prev['close'] if prev['close'] > 0 else 1.0
    day_gain = (curr['close'] - prev['close']) / prev_close_safe

    if abs(day_gain) > CONFIG["filter"]["max_day_change"]: 
        violations.append("RISK: å•æ—¥æ³¢åŠ¨è¿‡å¤§")
        
    if curr['RSI'] > CONFIG["filter"]["max_rsi"]: 
        violations.append("RISK: RSIä¸¥é‡è¶…ä¹°")
      
    if curr['BIAS_50'] > CONFIG["filter"]["max_bias_50"]:
        violations.append("RISK: ä¹–ç¦»ç‡è¿‡å¤§")

    if curr['Upper_Shadow_Ratio'] > CONFIG["filter"]["max_upper_shadow"]:
        violations.append("RISK: é•¿ä¸Šå½±çº¿å‹åŠ›")

    ny_now = datetime.now(MARKET_TIMEZONE)
    market_open = ny_now.replace(hour=9, minute=30, second=0, microsecond=0)
    minutes_elapsed = (ny_now - market_open).total_seconds() / 60
    is_open_market = 0 < minutes_elapsed < 390
      
    is_volume_ok = False
    proj_vol_final = curr['volume']
      
    # åªæœ‰ç›˜ä¸­æ£€æŸ¥é‡èƒ½ï¼Œç›˜å‰å·²è¢«å¤–éƒ¨å¾ªç¯å±è”½
    if is_open_market:
        if minutes_elapsed < 30:
            is_volume_ok = True 
        else:
            proj_factor = get_volume_projection_factor(ny_now, max(minutes_elapsed, 1))
            trend_modifier = 1 - (min(curr['ADX'], 40) - 20) / 200 
            proj_factor *= max(0.8, trend_modifier)
            proj_vol_final = curr['volume'] * proj_factor
            
            if proj_vol_final >= curr['Vol_MA20'] * CONFIG["filter"]["min_vol_ratio"]:
                is_volume_ok = True
    else:
        # ç›˜åå¤ç›˜ä½¿ç”¨
        if curr['volume'] >= curr['Vol_MA20'] * CONFIG["filter"]["min_vol_ratio"]:
            is_volume_ok = True
            
    if not is_volume_ok:
        # [ä¿®æ”¹] åˆ é™¤äº† (æ­»é±¼è‚¡)
        violations.append("FILTER: é‡èƒ½ä¸è¶³")

    if proj_vol_final > curr['Vol_MA20'] * 2.0:
        score += weights["HEAVY_VOLUME"]

    candle_patterns = detect_candle_patterns(df)
    if candle_patterns:
        triggers.append(f"Kçº¿: {', '.join(candle_patterns)}")
        score += weights["CANDLE_PATTERN"]

    # [ä¿®æ”¹é‡ç‚¹] BB Squeeze é€»è¾‘ä¿®æ”¹
    bb_min_width = CONFIG["filter"]["min_bb_squeeze_width"]
    bb_target_width = CONFIG["filter"]["min_bb_expand_width"] # ä½¿ç”¨æ–°çš„ç›®æ ‡å®½åº¦
    max_pos = CONFIG["filter"]["max_bottom_pos"]
    
    # è®¡ç®—å½“å‰ä»·æ ¼åœ¨è¿‡å»60å¤©å†…çš„ç›¸å¯¹ä½ç½® (0=Lowest, 1=Highest)
    if high_60 > low_60:
        price_pos = (curr['close'] - low_60) / (high_60 - low_60)
    else:
        price_pos = 0.5
      
    # é€»è¾‘: æ˜¨æ—¥æŒ¤å‹ + ä»Šæ—¥å˜å¤§åˆ°è¾¾æ ‡ + è‚¡ç¥¨ä¸Šæ¶¨(é˜³çº¿) + å¤„äºåº•éƒ¨
    if prev['BB_Width'] < bb_min_width: 
        if curr['BB_Width'] >= bb_target_width: # å®½åº¦å˜å¤§è¾¾åˆ°ç›®æ ‡
            if curr['close'] > curr['open']: # è‚¡ç¥¨æ˜¯ä¸Šæ¶¨çš„ (æ”¶é˜³)
                 if price_pos <= max_pos: # å¤„äºä½ä½
                    triggers.append(f"BB Squeeze: ä½ä½å¯åŠ¨ (å®½:{curr['BB_Width']:.3f}, ä½:{price_pos:.2f})")
                    score += weights["BB_SQUEEZE"]

    is_strong_trend = curr['ADX'] > 25 and curr['PDI'] > curr['MDI']
    is_adx_rising = curr['ADX'] > prev['ADX']
      
    if is_strong_trend and is_adx_rising:
        score += weights["STRONG_ADX"]
        
    recent_adx_min = df['ADX'].iloc[-10:-1].min()
    adx_activating = (recent_adx_min < 20) and \
                      (df['ADX'].iloc[-1] > df['ADX'].iloc[-2] > df['ADX'].iloc[-3])
                      
    if adx_activating:
        triggers.append(f"è¶‹åŠ¿æ¿€æ´»: ç›˜æ•´ç»“æŸ ADXæ‹å¤´")
        score += weights["ADX_ACTIVATION"]

    had_breakout = (df['close'].tail(10) > df['Nx_Blue_UP'].tail(10)).any()
    on_support = (curr['low'] >= curr['Nx_Blue_DW'] * 0.99) and (curr['close'] > curr['Nx_Blue_DW'])
      
    if is_strong_trend and had_breakout and on_support and (curr['close'] > curr['open']):
        triggers.append("Nx ç»“æ„: è“æ¢¯å›è¸©ç¡®è®¤")
        score += weights["GOD_TIER_NX"] 

    pattern_name, res_line, sup_line = identify_patterns(df)
    if pattern_name:
        triggers.append(pattern_name)
        score += weights["PATTERN_BREAK"]

    if prev['close'] < prev['Nx_Blue_UP'] and curr['close'] > curr['Nx_Blue_UP']:
        if curr['PDI'] > curr['MDI']:
            triggers.append(f"Nx çªç ´: ç«™ä¸Šè“æ¢¯")
            score += weights["NX_BREAKOUT"]
      
    is_zero_cross = prev['DIF'] < 0 and curr['DIF'] > 0 and curr['DIF'] > curr['DEA']
    if is_zero_cross:
        triggers.append(f"MACD é‡‘å‰")
        score += weights["MACD_ZERO_CROSS"]

    if prev['J'] < 0 and curr['J'] > 0 and curr['K'] > curr['D']:
        triggers.append(f"KDJ åå‡»")
        score += weights["KDJ_REBOUND"]
      
    price_low_20 = df['close'].tail(20).min()
    price_is_low = curr['close'] <= price_low_20 * 1.02
    macd_low_20 = df['MACD'].tail(20).min()
    if price_is_low and curr['MACD'] < 0:
        if curr['MACD'] > macd_low_20 * 0.8 and curr['DIF'] > df['DIF'].tail(20).min():
             triggers.append(f"MACD åº•èƒŒç¦»")
             score += weights["MACD_DIVERGE"]

    # [æ–°å¢] OBV éªŒè¯ä¿¡å· (èµ„é‡‘æµå…¥ç¡®è®¤)
    # é€»è¾‘: å½“å‰OBVé«˜äº20æ—¥å‡çº¿(è¶‹åŠ¿å‘ä¸Š) ä¸” å½“å‰OBVé«˜äº5å¤©å‰(è¿‘æœŸæµå…¥) ä¸” è‚¡ä»·æ”¶æ¶¨
    if curr['OBV'] > curr['OBV_MA20']:
        obv_rising = curr['OBV'] > df['OBV'].iloc[-5] # è¿‘æœŸä¹Ÿæ˜¯æ¶¨çš„
        if obv_rising and curr['close'] > curr['open']:
             triggers.append("èµ„é‡‘é¢: OBVè¶‹åŠ¿å‘ä¸Š (èµ„é‡‘æµå…¥)")
             score += weights["OBV_TREND_UP"]

    pinbar_ratio = (curr['close'] - curr['low']) / (curr['high'] - curr['low'] + 1e-9)
    market_cap = df.attrs.get('marketCap', float('inf')) 
      
    if curr['low'] < curr['BB_Low']:
        if proj_vol_final > curr['Vol_MA20'] * 2.5:
            if pinbar_ratio > 0.5 and market_cap < 5_000_000_000:
                triggers.append(f"æŠ›å”®é«˜æ½®")
                score += weights["CAPITULATION"]

    is_triggered = (score >= CONFIG["SCORE"]["MIN_ALERT_SCORE"]) and (len(violations) == 0)
      
    final_reason_parts = triggers + violations
    final_reason = "\n".join(final_reason_parts) if final_reason_parts else "æ— æ˜æ˜¾ä¿¡å·"

    return is_triggered, score, final_reason, res_line, sup_line

async def check_signals(df):
    return await asyncio.to_thread(check_signals_sync, df)

# [ä¿®æ”¹] æ¥æ”¶ stop_price å’Œ support_price
def _generate_chart_sync(df, ticker, res_line=[], sup_line=[], stop_price=None, support_price=None):
    buf = io.BytesIO()
      
    last_close = df['close'].iloc[-1]
      
    # é»˜è®¤å€¼ä¿æŠ¤
    if stop_price is None: stop_price = last_close * 0.95
    if support_price is None: support_price = last_close * 0.90

    s = mpf.make_marketcolors(up='r', down='g', inherit=True)
    my_style = mpf.make_mpf_style(base_mpl_style="ggplot", marketcolors=s, gridstyle=":")
    plot_df = df.tail(80)
      
    stop_line_data = [stop_price] * len(plot_df)
    supp_line_data = [support_price] * len(plot_df)

    add_plots = [
        mpf.make_addplot(plot_df['Nx_Blue_UP'], color='dodgerblue', width=1.0),
        mpf.make_addplot(plot_df['Nx_Blue_DW'], color='dodgerblue', width=1.0),
        mpf.make_addplot(plot_df['Nx_Yellow_UP'], color='gold', width=1.0),
        mpf.make_addplot(plot_df['Nx_Yellow_DW'], color='gold', width=1.0),
        
        # [ä¿®æ”¹] åŒçº¿ç»˜åˆ¶
        mpf.make_addplot(stop_line_data, color='red', linestyle='--', width=1.2),    # æ­¢æŸçº¿ (Red)
        mpf.make_addplot(supp_line_data, color='green', linestyle=':', width=1.2),   # æ”¯æ’‘çº¿ (Green)
        
        mpf.make_addplot(plot_df['MACD'], panel=2, type='bar', color='dimgray', alpha=0.5, ylabel='MACD'),
        mpf.make_addplot(plot_df['DIF'], panel=2, color='orange'),
        mpf.make_addplot(plot_df['DEA'], panel=2, color='blue'),
    ]
      
    kwargs = dict(type='candle', style=my_style, title=f"{ticker} Analysis", ylabel='Price', addplot=add_plots, volume=True, panel_ratios=(6, 2, 2), tight_layout=True, savefig=dict(fname=buf, format='png', bbox_inches='tight', pad_inches=0))
      
    all_lines = []
      
    if res_line: all_lines.extend(res_line)
    if sup_line: all_lines.extend(sup_line)
        
    if all_lines:
        kwargs['alines'] = dict(alines=all_lines, colors='darkgray', linewidths=1.5, linestyle='-.')
      
    try:
        mpf.plot(plot_df, **kwargs)
        buf.seek(0)
    finally:
        plt.close('all')
        
    return buf

async def generate_chart(df, ticker, res_line=[], sup_line=[], stop_price=None, support_price=None):
    return await asyncio.to_thread(_generate_chart_sync, df, ticker, res_line, sup_line, stop_price, support_price)

# [ä¿®æ”¹] å¢åŠ  10æ—¥ é€»è¾‘
async def update_stats_data():
    if "signal_history" not in settings: return
    updates_made = False
    symbols_to_check = set()
    history = settings["signal_history"]
    for date_str, tickers_data in history.items():
        try:
            signal_date = datetime.strptime(date_str, "%Y-%m-%d").date()
        except ValueError: continue
        today = datetime.now().date()
        if signal_date >= today: continue 
        for ticker, data in tickers_data.items():
            need_1d = data.get("ret_1d") is None
            need_5d = data.get("ret_5d") is None and (today - signal_date).days > 5
            # æ–°å¢ 10æ—¥
            need_10d = data.get("ret_10d") is None and (today - signal_date).days > 10
            need_20d = data.get("ret_20d") is None and (today - signal_date).days > 20
            if need_1d or need_5d or need_10d or need_20d: symbols_to_check.add(ticker)
            
    if not symbols_to_check: return
    data_map = await fetch_historical_batch(list(symbols_to_check), days=60)
    
    for date_str, tickers_data in history.items():
        signal_date = datetime.strptime(date_str, "%Y-%m-%d").date()
        for ticker, data in tickers_data.items():
            if ticker not in data_map: continue
            df = data_map[ticker]
            try:
                after_signal = df[df.index.date > signal_date]
                if after_signal.empty: continue
                signal_price = data['price']
                if signal_price <= 0: continue
                
                # 1D
                if data.get("ret_1d") is None and len(after_signal) >= 1:
                    price_1d = after_signal.iloc[0]['close']
                    data["ret_1d"] = round(((price_1d - signal_price) / signal_price) * 100, 2)
                    updates_made = True
                
                # 5D
                if data.get("ret_5d") is None and len(after_signal) >= 5:
                    price_5d = after_signal.iloc[4]['close'] 
                    data["ret_5d"] = round(((price_5d - signal_price) / signal_price) * 100, 2)
                    updates_made = True
                    
                # 10D
                if data.get("ret_10d") is None and len(after_signal) >= 10:
                    price_10d = after_signal.iloc[9]['close'] 
                    data["ret_10d"] = round(((price_10d - signal_price) / signal_price) * 100, 2)
                    updates_made = True

                # 20D
                if data.get("ret_20d") is None and len(after_signal) >= 20:
                    price_20d = after_signal.iloc[19]['close'] 
                    data["ret_20d"] = round(((price_20d - signal_price) / signal_price) * 100, 2)
                    updates_made = True
            except: pass
    if updates_made: save_settings()

def get_level_by_score(score): 
    if score >= 100: return CONFIG["SCORE"]["EMOJI"].get(100, "TOP")
    if score >= 90: return CONFIG["SCORE"]["EMOJI"].get(90, "HIGH")
    if score >= 80: return CONFIG["SCORE"]["EMOJI"].get(80, "MID")
    if score >= 70: return CONFIG["SCORE"]["EMOJI"].get(70, "LOW")
    return CONFIG["SCORE"]["EMOJI"].get(60, "TEST") 

# [ä¿®æ”¹] æ¥æ”¶ support å‚æ•°ï¼Œå¹¶æ˜¾ç¤ºåœ¨ Embed ä¸­
def create_alert_embed(ticker, score, price, reason, stop_loss, support, df, filename):
    level_str = get_level_by_score(score)
    if "RISK" in reason or "FILTER" in reason or "STALE" in reason:
        color = 0x95a5a6 
    else:
        color = 0x00ff00 if score >= 80 else 0x3498db
      
    # [ä¿®æ”¹ç‚¹] æ ‡é¢˜æ”¹ä¸º "ğŸš¨TSLA æŠ„åº•ä¿¡å· | å¾—åˆ† 15" æ ¼å¼
    embed = discord.Embed(title=f"ğŸš¨{ticker} æŠ„åº•ä¿¡å· | å¾—åˆ† {score}", color=color)
    
    # [ä¿®æ”¹ç‚¹] æ¢å¤ç°ä»·
    embed.description = f"**ç°ä»·:** `${price:.2f}`"
      
    curr = df.iloc[-1]
      
    ny_now = datetime.now(MARKET_TIMEZONE)
    market_open = ny_now.replace(hour=9, minute=30, second=0, microsecond=0)
    minutes_elapsed = (ny_now - market_open).total_seconds() / 60
      
    # [ä¿®æ”¹ç‚¹] é‡æ¯”åŠ ä¸Š (é¢„ä¼°)
    vol_label = "**é‡æ¯” (é¢„ä¼°):**"
    vol_ratio = 0.0
      
    if 0 < minutes_elapsed < 390:
        proj_factor = get_volume_projection_factor(ny_now, max(minutes_elapsed, 1))
        projected_vol = curr['volume'] * proj_factor
        vol_ratio = projected_vol / df['Vol_MA20'].iloc[-1]
    else:
        vol_ratio = curr['volume'] / df['Vol_MA20'].iloc[-1]
      
    # [æ–°å¢] OBV çŠ¶æ€æ–‡æœ¬
    obv_status = "æµå…¥" if curr['OBV'] > curr['OBV_MA20'] else "æµå‡º"
    
    # [ä¿®æ”¹ç‚¹] åˆ é™¤äº† MACDï¼Œåˆ é™¤äº†æ ‡é¢˜ï¼ˆä½¿ç”¨ \u200bï¼‰
    indicator_text = (
        f"**RSI(14):** `{curr['RSI']:.1f}`\n"
        f"**ADX:** `{curr['ADX']:.1f}`\n"
        f"{vol_label} `{vol_ratio:.1f}x`\n" 
        f"**OBV:** `{obv_status}`\n"
        f"**Bias(50):** `{curr['BIAS_50']*100:.1f}%`"
    )
    embed.add_field(name="\u200b", value=indicator_text, inline=True)
      
    # [ä¿®æ”¹ç‚¹] åˆ é™¤äº†å»ºè®®ä»“ä½ï¼Œåˆ é™¤äº†æ ‡é¢˜ï¼ˆä½¿ç”¨ \u200bï¼‰
    risk_text = (
        f"**æ­¢æŸä»·:** `${stop_loss:.2f}`\n"
        f"**æ”¯æ’‘ä½:** `${support:.2f}`\n"
    )
    embed.add_field(name="\u200b", value=risk_text, inline=True)
      
    # [ä¿®æ”¹ç‚¹] å°†â€œè§¦å‘è¯¦æƒ…â€æ ‡é¢˜æ”¹ä¸º \u200b (ç©ºå­—ç¬¦)ï¼Œéšè—æ ‡é¢˜ä½†ä¿ç•™å†…å®¹
    embed.add_field(name="\u200b", value=f"```{reason}```", inline=False)
      
    embed.set_image(url=f"attachment://{filename}")
    
    # [ä¿®æ”¹ç‚¹] å®Œå…¨åˆ é™¤ Footer
    # embed.set_footer(text=...) 
      
    return embed

class StockBotClient(discord.Client):
    def __init__(self, *, intents: discord.Intents):
        super().__init__(intents=intents)
        self.tree = app_commands.CommandTree(self)
        self.alert_channel = None
        self.last_report_date = None

    async def on_ready(self):
        load_settings()
        logging.info(f'Logged in as {self.user}')
        if ALERT_CHANNEL_ID != 0:
            self.alert_channel = self.get_channel(ALERT_CHANNEL_ID)
            if self.alert_channel is None:
                logging.error(f"Could not find channel with ID {ALERT_CHANNEL_ID}")
        else:
            logging.warning("No ALERT_CHANNEL_ID provided in env.")
            
        if not self.monitor_stocks.is_running():
            self.monitor_stocks.start()
        
        # [æ–°å¢] å¯åŠ¨å®šæ—¶æŠ¥å‘Šä»»åŠ¡
        if not self.scheduled_report.is_running():
            self.scheduled_report.start()
            
        await self.tree.sync()

    # [ä¿®æ”¹] å‘é€æ¯æ—¥å›æµ‹æŠ¥å‘Šé€»è¾‘
    async def send_daily_stats_report(self):
        if not self.alert_channel: return
        
        logging.info("Generating daily backtest report...")
        await update_stats_data()
        load_settings()
        
        history = settings.get("signal_history", {})
        
        # [ä¿®æ”¹] æ”¹ç”¨æ–°çš„ fetch_market_index_data è·å– ^IXIC
        market_df = await fetch_market_index_data(days=80)

        def get_market_ret(date_str, offset_days):
            if market_df is None or market_df.empty: return None
            try:
                target_date = pd.to_datetime(date_str).normalize()
                # æ‰¾åˆ°å¯¹åº”æ—¥æœŸåœ¨ index ä¸­çš„ä½ç½®
                idx = market_df.index.get_indexer([target_date], method='nearest')[0]
                
                # ç¡®ä¿ç´¢å¼•æ²¡æœ‰è¶Šç•Œ
                if idx + offset_days < len(market_df):
                    # [æ³¨æ„] Light API è¿”å›çš„æ˜¯ 'price' å­—æ®µ
                    p_start = market_df.iloc[idx]['price']
                    p_end = market_df.iloc[idx + offset_days]['price']
                    return ((p_end - p_start) / p_start) * 100
            except: pass
            return None

        # åˆå§‹åŒ–ç»Ÿè®¡å®¹å™¨: åˆ†ç¦»ä¸ªè‚¡(s)å’Œå¤§ç›˜(m)çš„ç»Ÿè®¡
        stats_agg = {k: {"s_sum": 0.0, "s_c": 0, "m_sum": 0.0, "m_c": 0, "w": 0} for k in ["1d", "5d", "10d", "20d"]}
        
        valid_signals = []
        if history:
            sorted_dates = sorted(history.keys(), reverse=True)
            today = datetime.now().date()
            
            for date_str in sorted_dates:
                try:
                    sig_date = datetime.strptime(date_str, "%Y-%m-%d").date()
                except: continue
                if (today - sig_date).days > 25: continue # ç¨å¾®æ”¾å®½ä¸€ç‚¹èŒƒå›´
                
                tickers_data = history[date_str]
                for ticker, data in tickers_data.items():
                    if data.get("score", 0) == 0: continue # è¿‡æ»¤ TEST
                    
                    score = data.get("score", 0)
                    valid_signals.append((date_str, ticker, score, data))
                    
                    for k, days_off in [("1d", 1), ("5d", 5), ("10d", 10), ("20d", 20)]:
                        # 1. è®¡ç®—å¤§ç›˜æ•°æ® (æ— æ¡ä»¶ï¼Œåªè¦æœ‰ä¿¡å·æ—¥æœŸ)
                        m = get_market_ret(date_str, days_off)
                        if m is not None:
                            stats_agg[k]["m_sum"] += m
                            stats_agg[k]["m_c"] += 1
                        
                        # 2. è®¡ç®—ä¸ªè‚¡æ•°æ®
                        r = data.get(f"ret_{k}")
                        if r is not None:
                            stats_agg[k]["s_sum"] += r
                            stats_agg[k]["s_c"] += 1
                            if r > 0: stats_agg[k]["w"] += 1
        else:
            # [Fix 3] å³ä½¿æ²¡æœ‰å†å²æ•°æ®ï¼Œä¹Ÿå°è¯•è®¡ç®—æœ€è¿‘çš„å¤§ç›˜èµ°åŠ¿ä½œä¸ºå‚è€ƒ
            # è¿™é‡Œçš„é€»è¾‘æ˜¯ï¼šå¦‚æœå®Œå…¨æ²¡æœ‰å†å²ä¿¡å·ï¼Œå°±æ‹¿å¤§ç›˜æœ€è¿‘çš„ 1,5,10,20 å¤©å‰çš„æ¶¨å¹…å¡«è¿›å»
            if market_df is not None and not market_df.empty:
                last_idx = -1 # æœ€è¿‘çš„ä¸€å¤©
                # å€’æ¨æ¨¡æ‹Ÿæ•°æ®
                # å®é™…ä¸Šè¿™ä¸ªåœºæ™¯æ¯”è¾ƒç‰¹æ®Šï¼Œæˆ‘ä»¬é€‰æ‹©ç›´æ¥åœ¨ Embed æ˜¾ç¤ºæ—¶å¤„ç† "ç­‰å¾…æ•°æ®"
                pass

        # [Fix 2] åˆ é™¤äº†æ ‡é¢˜ä¸­çš„ (vs ^IXIC)
        embed = discord.Embed(title="å›æµ‹ç»Ÿè®¡", color=0x9b59b6)
        
        # [é‡ç‚¹] æ¢å¤æ ¸å¿ƒæ•°æ®è¡Œ
        def mk_field(key):
            d = stats_agg[key]
            
            # ä¸ªè‚¡éƒ¨åˆ†
            if d["s_c"] > 0:
                avg_stock = d["s_sum"] / d["s_c"]
                avg_stock_str = f"`{avg_stock:+.2f}%`"
                win_rate = f"`{d['w']/d['s_c']*100:.0f}%`"
            else:
                avg_stock = None
                avg_stock_str = "Wait..."
                win_rate = "-"

            # å¤§ç›˜éƒ¨åˆ† (å³ä½¿ä¸ªè‚¡æ²¡æ•°æ®ï¼Œåªè¦æœ‰ m_c ä¹Ÿæ˜¾ç¤º)
            if d["m_c"] > 0:
                avg_market = d["m_sum"] / d["m_c"]
                avg_market_str = f"`{avg_market:+.2f}%`"
            else:
                # [Fix 3] å¦‚æœè¿ä¿¡å·éƒ½æ²¡ï¼Œå°è¯•è·å–å¤§ç›˜æœ€è¿‘èµ°åŠ¿ (Trailing)
                if d["s_c"] == 0 and market_df is not None and not market_df.empty:
                    # è®¡ç®—å¤§ç›˜ Trailing Return
                    try:
                        days_offset = int(key[:-1])
                        if len(market_df) > days_offset:
                            p_now = market_df.iloc[-1]['price']
                            p_prev = market_df.iloc[-(days_offset+1)]['price']
                            val = ((p_now - p_prev) / p_prev) * 100
                            avg_market = val
                            avg_market_str = f"`{val:+.2f}%`"
                        else:
                            avg_market = None
                            avg_market_str = "Wait..."
                    except:
                        avg_market = None
                        avg_market_str = "Wait..."
                else:
                    avg_market = None
                    avg_market_str = "Wait..."

            # è¶…é¢æ”¶ç›Š
            if avg_stock is not None and avg_market is not None and isinstance(avg_market, float):
                diff = avg_stock - avg_market
                diff_str = f"**{diff:+.2f}%**"
            else:
                diff_str = "-"
            
            return f"ä¸ªè‚¡å¹³å‡: {avg_stock_str}\nçº³æŒ‡åŒæœŸ: {avg_market_str}\nè¶…é¢æ”¶ç›Š: {diff_str}\nä¸ªè‚¡èƒœç‡: {win_rate}"

        embed.add_field(name="1æ—¥è¡¨ç°", value=mk_field("1d"), inline=True)
        embed.add_field(name="5æ—¥è¡¨ç°", value=mk_field("5d"), inline=True)
        embed.add_field(name="10æ—¥è¡¨ç°", value=mk_field("10d"), inline=True)
        embed.add_field(name="20æ—¥è¡¨ç°", value=mk_field("20d"), inline=True)
        
        recent_list_str = []
        for date_str, ticker, score, data in valid_signals[:5]:
            r1 = data.get("ret_1d")
            r1_str = f"{r1:+.1f}%" if r1 is not None else "-"
            r5 = data.get("ret_5d")
            r5_str = f"{r5:+.1f}%" if r5 is not None else "-"
            r10 = data.get("ret_10d")
            r10_str = f"{r10:+.1f}%" if r10 is not None else "-"
            r20 = data.get("ret_20d")
            r20_str = f"{r20:+.1f}%" if r20 is not None else "-"
            
            recent_list_str.append(f"`{date_str}` **{ticker}**\nâ”” 1D:`{r1_str}` 5D:`{r5_str}` 10D:`{r10_str}` 20D:`{r20_str}`")
        
        if recent_list_str:
            embed.add_field(name="è¯¦ç»†æƒ…å†µ", value="\n".join(recent_list_str), inline=False)
        else:
            embed.add_field(name="è¯¦ç»†æƒ…å†µ", value="æ— è¿‘æœŸä¿¡å·", inline=False)

        embed.set_footer(text=f"Report generated at {datetime.now(MARKET_TIMEZONE).strftime('%H:%M:%S')} ET")
        await self.alert_channel.send(embed=embed)

    # [æ–°å¢] æ¯å¤©æ”¶ç›˜ååŠå°æ—¶ (16:30 ET) è‡ªåŠ¨å‘é€å›æµ‹æŠ¥å‘Š
    @tasks.loop(minutes=1)
    async def scheduled_report(self):
        now_et = datetime.now(MARKET_TIMEZONE)
        # æ£€æŸ¥æ˜¯å¦æ˜¯ 16:30
        if now_et.hour == 16 and now_et.minute == 30:
            today_date = now_et.date()
            if self.last_report_date != today_date:
                await self.send_daily_stats_report()
                self.last_report_date = today_date

    @tasks.loop(minutes=5)
    async def monitor_stocks(self):
        if not self.alert_channel: return
        now_et = datetime.now(MARKET_TIMEZONE)
        curr_time, today_str = now_et.time(), now_et.strftime('%Y-%m-%d')
        
        # [ä¿®æ”¹] åˆ é™¤ pre-market åˆ¤æ–­ï¼Œåªä¿ç•™ 10:00 åçš„æ‰«æ
        is_open_scan = TIME_MARKET_SCAN_START <= curr_time <= TIME_MARKET_CLOSE
        
        if not is_open_scan: return
        
        logging.info(f"[{now_et.strftime('%H:%M')}] Scanning started...")
        users_data = settings.get("users", {})
        all_tickers = set()
        ticker_user_map = defaultdict(list)
        
        for uid, udata in users_data.items():
            for k in list(udata['daily_status'].keys()):
                if not k.endswith(today_str): del udata['daily_status'][k]
            for ticker in udata.get("stocks", []):
                all_tickers.add(ticker)
                ticker_user_map[ticker].append(uid)

        if not all_tickers: 
            logging.info("No tickers to scan.")
            return

        hist_map = await fetch_historical_batch(list(all_tickers))
        quotes_map = {}
        if TIME_MARKET_OPEN <= curr_time <= TIME_MARKET_CLOSE:
            quotes_map = await fetch_realtime_quotes(list(all_tickers))

        alerts_buffer = []
        if "signal_history" not in settings: settings["signal_history"] = {}
        if today_str not in settings["signal_history"]: settings["signal_history"][today_str] = {}

        for ticker, df_hist in hist_map.items():
            df = df_hist
            if ticker in quotes_map:
                df = await asyncio.to_thread(merge_and_recalc_sync, df_hist, quotes_map[ticker])
            
            # å¦‚æœåˆå¹¶å¤±è´¥å¯¼è‡´dfä¸ºç©ºï¼Œè·³è¿‡
            if df is None or df.empty: continue

            user_ids = ticker_user_map[ticker]
            all_alerted = True
            users_to_ping = []
            for uid in user_ids:
                status_key = f"{ticker}-{today_str}"
                status = users_data[uid]['daily_status'].get(status_key, "NONE")
                # åªæœ‰ NONE çŠ¶æ€æ‰ä¼šå‘ (å³å½“å¤©ç¬¬ä¸€æ¬¡)
                if status == "NONE":
                    users_to_ping.append(uid)
                    all_alerted = False
            
            if all_alerted: continue

            history = settings.get("signal_history", {})
            in_cooldown = False
            cooldown_days = CONFIG["system"]["cooldown_days"]
            last_signal_score = 0
            
            for i in range(1, cooldown_days + 1): 
                past_date = (now_et.date() - timedelta(days=i)).strftime("%Y-%m-%d")
                if past_date in history and ticker in history[past_date]:
                    last_signal_score = history[past_date][ticker].get("score", 0)
                    in_cooldown = True 
            
            is_triggered, score, reason, res_line, sup_line = await check_signals(df)
            
            today_signal_data = settings["signal_history"][today_str].get(ticker)
            if today_signal_data:
                today_score = today_signal_data.get("score", 0)
                if score <= today_score:
                    is_triggered = False
                    logging.info(f"Ticker {ticker} skipped because a signal with score {today_score} was already sent today.")

            if is_triggered and in_cooldown and last_signal_score > 0:
                if score <= last_signal_score:
                    logging.info(f"Ticker {ticker} skipped due to cooldown (Last Score: {last_signal_score}).")
                    is_triggered = False
            
            if is_triggered:
                price = df['close'].iloc[-1]
                
                # [ä¿®æ”¹] è®¡ç®—åŒçº¿
                stop_loss, support = calculate_risk_levels(df)
                
                alert_obj = {
                    "ticker": ticker,
                    "score": score, 
                    "priority": score, 
                    "price": price,
                    "reason": reason,
                    "support": support,
                    "stop_loss": stop_loss, # æ–°å¢
                    "df": df,
                    "res_line": res_line,
                    "sup_line": sup_line,
                    "users": users_to_ping
                }
                alerts_buffer.append(alert_obj)

        if alerts_buffer:
            alerts_buffer.sort(key=lambda x: x["priority"], reverse=True)
            max_charts = CONFIG["system"]["max_charts_per_scan"]
            sent_charts = 0
            summary_list = []

            for alert in alerts_buffer:
                ticker = alert["ticker"]
                score = alert["score"]
                users = alert["users"]
                
                current_hist = settings["signal_history"][today_str].get(ticker, {})
                settings["signal_history"][today_str][ticker] = {
                    "score": score,
                    "price": alert["price"],
                    "time": now_et.strftime('%H:%M'),
                    "reason": alert["reason"],
                    "ret_1d": current_hist.get("ret_1d"),
                    "ret_5d": current_hist.get("ret_5d"),
                    "ret_10d": current_hist.get("ret_10d"), # è®°å½• 10d
                    "ret_20d": current_hist.get("ret_20d"),
                }
                
                for uid in users:
                    status_key = f"{ticker}-{today_str}"
                    users_data[uid]['daily_status'][status_key] = "MARKET_SENT"
                
                mentions = " ".join([f"<@{uid}>" for uid in users])
                
                if sent_charts < max_charts:
                    # [ä¿®æ”¹] ä¼ é€’åŒçº¿ç»™ç”»å›¾
                    chart_buf = await generate_chart(
                        alert["df"], ticker, alert["res_line"], alert["sup_line"], 
                        alert["stop_loss"], alert["support"]
                    )
                    filename = f"{ticker}.png"
                    
                    embed = create_alert_embed(
                        ticker, score, alert['price'], alert['reason'], 
                        alert['stop_loss'], alert['support'], alert['df'], filename
                    )
                    
                    try:
                        file = discord.File(chart_buf, filename=filename)
                        await self.alert_channel.send(content=mentions, embed=embed, file=file)
                        sent_charts += 1
                        await asyncio.sleep(1.5)
                    except Exception as e: logging.error(f"Send Error: {e}")
                    finally:
                        chart_buf.close() 
                else:
                    summary_list.append(f"**{ticker}** ({score})")

            if summary_list:
                summary_msg = f"**å…¶ä»–æé†’ (æ‘˜è¦)**:\n" + " | ".join(summary_list)
                try: 
                    await self.alert_channel.send(content=summary_msg)
                except: pass
            
            save_settings()
        
        logging.info(f"[{now_et.strftime('%H:%M')}] Scan finished. Alerts: {len(alerts_buffer)}")

intents = discord.Intents.default()
client = StockBotClient(intents=intents)

# [æ–°å¢] é‡ç½®ç»Ÿè®¡å‘½ä»¤
@client.tree.command(name="reset_stats", description="Reset all backtest statistics")
async def reset_stats(interaction: discord.Interaction):
    global settings
    settings["signal_history"] = {}
    save_settings()
    await interaction.response.send_message("Statistics reset.", ephemeral=True)

@client.tree.command(name="watch_add", description="Add stocks to watch list (e.g., AAPL, TSLA)")
@app_commands.describe(codes="Stock Symbols")
async def watch_add(interaction: discord.Interaction, codes: str):
    await interaction.response.defer()
    user_data = get_user_data(interaction.user.id)
    new_list = list(set([t.strip().upper() for t in codes.replace(',', ' ').replace('ï¼Œ', ' ').split() if t.strip()]))
    current_set = set(user_data["stocks"])
    current_set.update(new_list)
    user_data["stocks"] = list(current_set)
    save_settings()
    await interaction.followup.send(f"Added: `{', '.join(new_list)}`")

@client.tree.command(name="watch_remove", description="Remove stocks from watch list")
@app_commands.describe(codes="Stock Symbols")
async def watch_remove(interaction: discord.Interaction, codes: str):
    await interaction.response.defer()
    user_data = get_user_data(interaction.user.id)
    to_remove = set([t.strip().upper() for t in codes.replace(',', ' ').replace('ï¼Œ', ' ').split() if t.strip()])
    current_list = user_data["stocks"]
    new_list = [s for s in current_list if s not in to_remove]
    user_data["stocks"] = new_list
    for t in to_remove:
        keys_to_del = [k for k in user_data['daily_status'] if k.startswith(t)]
        for k in keys_to_del: del user_data['daily_status'][k]
    save_settings()
    await interaction.followup.send(f"Removed: `{', '.join(to_remove)}`")

@client.tree.command(name="watch_list", description="Show my watch list")
async def watch_list(interaction: discord.Interaction):
    stocks = get_user_data(interaction.user.id)["stocks"]
    if len(stocks) > 60: display_str = ", ".join(stocks[:60]) + f"... ({len(stocks)})"
    else: display_str = ", ".join(stocks) if stocks else 'Empty'
    await interaction.response.send_message(f"List:\n`{display_str}`", ephemeral=True)

@client.tree.command(name="watch_clear", description="Clear all watched stocks")
async def watch_clear(interaction: discord.Interaction):
    user_data = get_user_data(interaction.user.id)
    user_data["stocks"] = []
    user_data["daily_status"] = {}
    save_settings()
    await interaction.response.send_message("Cleared.", ephemeral=True)

@client.tree.command(name="watch_import", description="Import preset lists")
@app_commands.choices(preset=[
    app_commands.Choice(name="NASDAQ 100", value="NASDAQ_100"),
    app_commands.Choice(name="GOD TIER", value="GOD_TIER")
])
async def watch_import(interaction: discord.Interaction, preset: app_commands.Choice[str]):
    await interaction.response.defer()
    user_data = get_user_data(interaction.user.id)
    new_list = STOCK_POOLS.get(preset.value, [])
    current_set = set(user_data["stocks"])
    current_set.update(new_list)
    user_data["stocks"] = list(current_set)
    save_settings()
    await interaction.followup.send(f"Imported {preset.name} ({len(new_list)} stocks).")

# [ä¿®æ”¹] å‡çº§ç‰ˆç»Ÿè®¡å‘½ä»¤ (20å¤©å»é‡ + çº³æ–¯è¾¾å…‹ ^IXIC å¯¹æ¯”)
@client.tree.command(name="stats", description="View historical signal accuracy (20-day window)")
async def stats_command(interaction: discord.Interaction):
    await interaction.response.defer()
    
    # 1. ç¡®ä¿ä¸ªè‚¡æ”¶ç›Šæ•°æ®æ˜¯æœ€æ–°çš„
    await update_stats_data()
    
    load_settings()
    history = settings.get("signal_history", {})
    # [ä¿®æ”¹] å³ä½¿æ²¡æœ‰ history ä¹Ÿä¸ç›´æ¥è¿”å›ï¼Œä¸ºäº†æ˜¾ç¤ºå¤§ç›˜ Trailing æ•°æ®
    
    # 2. [ä¿®æ”¹] æŠ“å–çº³æ–¯è¾¾å…‹ (^IXIC) æ•°æ®ä½œä¸ºåŸºå‡†
    market_df = await fetch_market_index_data(days=80)

    def get_market_ret(date_str, offset_days):
        if market_df is None or market_df.empty: return None
        try:
            target_date = pd.to_datetime(date_str).normalize()
            idx = market_df.index.get_indexer([target_date], method='nearest')[0]
            if idx + offset_days < len(market_df):
                # [æ³¨æ„] è¿™é‡Œä½¿ç”¨ price
                p_start = market_df.iloc[idx]['price']
                p_end = market_df.iloc[idx + offset_days]['price']
                return ((p_end - p_start) / p_start) * 100
        except:
            pass
        return None

    # 3. ç­›é€‰ä¸ç»Ÿè®¡
    # s_sum: stock sum, s_c: stock count, m_sum: market sum, m_c: market count
    stats_agg = {
        k: {"s_sum": 0.0, "s_c": 0, "m_sum": 0.0, "m_c": 0, "w": 0} 
        for k in ["1d", "5d", "10d", "20d"]
    }
    
    seen_tickers = set()
    valid_signals = []
    
    sorted_dates = sorted(history.keys(), reverse=True)
    today = datetime.now().date()
    
    for date_str in sorted_dates:
        try:
            sig_date = datetime.strptime(date_str, "%Y-%m-%d").date()
        except: continue
        
        days_diff = (today - sig_date).days
        if days_diff > 25: continue
        
        tickers_data = history[date_str]
        for ticker, data in tickers_data.items():
            if data.get("score", 0) == 0: continue

            if ticker in seen_tickers: continue
            seen_tickers.add(ticker)
            
            score = data.get("score", 0)
            valid_signals.append((date_str, ticker, score, data))
            
            # ç´¯åŠ ç»Ÿè®¡æ•°æ®
            for k, days_off in [("1d", 1), ("5d", 5), ("10d", 10), ("20d", 20)]:
                # [Fix 3] ç‹¬ç«‹ç´¯åŠ å¤§ç›˜æ•°æ®
                m = get_market_ret(date_str, days_off) 
                if m is not None:
                    stats_agg[k]["m_sum"] += m
                    stats_agg[k]["m_c"] += 1

                # ç‹¬ç«‹ç´¯åŠ ä¸ªè‚¡æ•°æ®
                r = data.get(f"ret_{k}")
                if r is not None:
                    stats_agg[k]["s_sum"] += r
                    stats_agg[k]["s_c"] += 1
                    if r > 0: stats_agg[k]["w"] += 1

    # 4. æ„å»º Embed
    # [Fix 2] æ ‡é¢˜ä¿®æ”¹
    embed = discord.Embed(title="å›æµ‹ç»Ÿè®¡", color=0x00BFFF)
    
    def mk_field(key):
        d = stats_agg[key]
        
        # ä¸ªè‚¡éƒ¨åˆ†
        if d["s_c"] > 0:
            avg_stock = d["s_sum"] / d["s_c"]
            avg_stock_str = f"`{avg_stock:+.2f}%`"
            win_rate = f"`{d['w']/d['s_c']*100:.0f}%`"
        else:
            avg_stock = None
            avg_stock_str = "Wait..."
            win_rate = "-"

        # å¤§ç›˜éƒ¨åˆ† (åªè¦ m_c > 0 å°±æ˜¾ç¤ºï¼Œä¸ç”¨ç®¡ s_c)
        if d["m_c"] > 0:
            avg_market = d["m_sum"] / d["m_c"]
            avg_market_str = f"`{avg_market:+.2f}%`"
        else:
            # [Fix 3] æ— ä¿¡å·æ—¶ï¼Œæ˜¾ç¤ºæœ€è¿‘çš„å¤§ç›˜è¶‹åŠ¿
            if d["s_c"] == 0 and market_df is not None and not market_df.empty:
                try:
                    days_offset = int(key[:-1])
                    if len(market_df) > days_offset:
                        p_now = market_df.iloc[-1]['price']
                        p_prev = market_df.iloc[-(days_offset+1)]['price']
                        val = ((p_now - p_prev) / p_prev) * 100
                        avg_market = val
                        avg_market_str = f"`{val:+.2f}%`"
                    else:
                        avg_market = None
                        avg_market_str = "Wait..."
                except:
                    avg_market = None
                    avg_market_str = "Wait..."
            else:
                avg_market = None
                avg_market_str = "Wait..."

        # è¶…é¢æ”¶ç›Š
        if avg_stock is not None and avg_market is not None and isinstance(avg_market, float):
            diff = avg_stock - avg_market
            diff_str = f"**{diff:+.2f}%**"
        else:
            diff_str = "-"
        
        return (
            f"ä¸ªè‚¡å¹³å‡: {avg_stock_str}\n"
            f"çº³æŒ‡åŒæœŸ: {avg_market_str}\n"
            f"è¶…é¢æ”¶ç›Š: {diff_str}\n"
            f"ä¸ªè‚¡èƒœç‡: {win_rate}"
        )

    embed.add_field(name="1æ—¥è¡¨ç°", value=mk_field("1d"), inline=True)
    embed.add_field(name="5æ—¥è¡¨ç°", value=mk_field("5d"), inline=True)
    embed.add_field(name="10æ—¥è¡¨ç°", value=mk_field("10d"), inline=True)
    embed.add_field(name="20æ—¥è¡¨ç°", value=mk_field("20d"), inline=True)

    recent_list_str = []
    for date_str, ticker, score, data in valid_signals[:10]:
        r1 = data.get("ret_1d")
        r1_str = f"{r1:+.1f}%" if r1 is not None else "-"
        r5 = data.get("ret_5d")
        r5_str = f"{r5:+.1f}%" if r5 is not None else "-"
        r10 = data.get("ret_10d")
        r10_str = f"{r10:+.1f}%" if r10 is not None else "-"
        r20 = data.get("ret_20d")
        r20_str = f"{r20:+.1f}%" if r20 is not None else "-"
        
        recent_list_str.append(f"`{date_str}` **{ticker}**\nâ”” 1D:`{r1_str}` 5D:`{r5_str}` 10D:`{r10_str}` 20D:`{r20_str}`")
        
    if recent_list_str:
        embed.add_field(name="è¯¦ç»†æƒ…å†µ", value="\n".join(recent_list_str), inline=False)
    else:
        embed.add_field(name="è¯¦ç»†æƒ…å†µ", value="æ— è¿‘æœŸä¿¡å·", inline=False)
        
    await interaction.followup.send(embed=embed)

@client.tree.command(name="test", description="Test single stock")
async def test_command(interaction: discord.Interaction, ticker: str):
    await interaction.response.defer()
    ticker = ticker.upper().strip()
    
    logging.info(f"[TEST Command] Testing: {ticker}")

    data_map = await fetch_historical_batch([ticker])
    quotes_map = await fetch_realtime_quotes([ticker])
    
    if not data_map or ticker not in data_map:
        await interaction.followup.send(f"Failed `{ticker}` (Check logs for 403/429 or data error)")
        return
        
    df = data_map[ticker]
    if ticker in quotes_map:
        df = await asyncio.to_thread(merge_and_recalc_sync, df, quotes_map[ticker])

    is_triggered, score, reason, r_l, s_l = await check_signals(df)
    
    price = df['close'].iloc[-1]
    
    # [ä¿®æ”¹] è®¡ç®—åŒçº¿
    stop_loss, support = calculate_risk_levels(df)

    if not reason: 
        reason = f"æ— æ˜æ˜¾ä¿¡å· (å¾—åˆ†: {score})"
    
    # [ä¿®æ”¹] ä¼ é€’åŒçº¿ç»™ç”»å›¾
    chart_buf = await generate_chart(df, ticker, r_l, s_l, stop_loss, support)
    filename = f"{ticker}_test.png"
    
    # [ä¿®æ”¹] ä¼ é€’åŒçº¿ç»™ Embed
    embed = create_alert_embed(ticker, score, price, reason, stop_loss, support, df, filename)

    try:
        f = discord.File(chart_buf, filename=filename)
        await interaction.followup.send(embed=embed, file=f)
    except Exception as e:
        logging.error(f"Send Error: {e}")
        await interaction.followup.send(f"Failed to send image: {e}")
    finally:
        chart_buf.close()

if __name__ == "__main__":
    if DISCORD_TOKEN: client.run(DISCORD_TOKEN)
